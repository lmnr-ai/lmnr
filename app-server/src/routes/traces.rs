use super::ResponseResult;
use crate::{
    ch::{
        self,
        spans::{get_time_bounds, IntMetricTimeValue},
        utils::hours_ago,
    },
    db::{
        self,
        events::EventWithTemplateName,
        metrics::Aggregation,
        modifiers::{DateRange, Filter, GroupByInterval},
        trace::{Span, Trace, TraceWithEvents},
        DB,
    },
};
use actix_web::{get, post, web, HttpResponse};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use uuid::Uuid;

const DEFAULT_PAGE_SIZE: usize = 50;

#[derive(Deserialize, Debug)]
#[serde(rename_all = "camelCase")]
struct GetTracesQueryParams {
    /// page number starting from 0
    #[serde(default)]
    page_number: usize,
    page_size: Option<usize>,
    #[serde(default)]
    filter: Value,
    #[serde(default)]
    #[serde(flatten)]
    pub date_range: Option<DateRange>,
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
struct GetTracesResponse {
    total_entries: i64,
    traces: Vec<TraceWithEvents>,
    total_in_project: Option<i64>,
}

/// Get traces generated by Laminar tracing
#[get("traces")]
pub async fn get_traces(
    path: web::Path<Uuid>,
    db: web::Data<DB>,
    query_params: web::Query<GetTracesQueryParams>,
) -> ResponseResult {
    let project_id = path.into_inner();
    let query_params = query_params.into_inner();
    let limit = query_params.page_size.unwrap_or(DEFAULT_PAGE_SIZE);
    let offset = limit * (query_params.page_number);
    let filters = Filter::from_url_params(query_params.filter);
    let date_range = query_params.date_range;

    let traces = db::trace::get_traces(
        &db.pool,
        project_id,
        limit,
        offset,
        filters.clone(),
        date_range.as_ref(),
    )
    .await?;
    let total_entries =
        db::trace::count_traces(&db.pool, project_id, filters, date_range.as_ref()).await?;
    let total_in_project = if total_entries == 0 {
        Some(db::trace::count_all_traces_in_project(&db.pool, project_id).await?)
    } else {
        None
    };

    let response = GetTracesResponse {
        total_entries,
        traces,
        total_in_project,
    };

    Ok(HttpResponse::Ok().json(response))
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct TraceWithSpanPreviews {
    #[serde(flatten)]
    pub trace: Trace,
    pub spans: Vec<Span>,
}

/// Get a single trace generated by Laminar tracing instrumentation
#[get("traces/{trace_id}")]
pub async fn get_single_trace(
    params: web::Path<(Uuid, Uuid)>,
    db: web::Data<DB>,
) -> ResponseResult {
    let (_project_id, trace_id) = params.into_inner();

    let trace = db::trace::get_single_trace(&db.pool, trace_id).await?;
    let span_previews = db::trace::get_span_previews(&db.pool, trace_id).await?;

    let trace_with_spans = TraceWithSpanPreviews {
        trace,
        spans: span_previews,
    };

    Ok(HttpResponse::Ok().json(trace_with_spans))
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
pub struct SpanWithEvents {
    #[serde(flatten)]
    pub span: Span,
    pub events: Vec<EventWithTemplateName>,
}

/// Get a single span generated by Laminar tracing instrumentation
#[get("spans/{span_id}")]
pub async fn get_single_span(params: web::Path<(Uuid, Uuid)>, db: web::Data<DB>) -> ResponseResult {
    let (_project_id, span_id) = params.into_inner();

    let span = db::trace::get_span(&db.pool, span_id).await?;
    let events = db::events::get_events_for_span(&db.pool, span_id).await?;

    let span_with_events = SpanWithEvents { span, events };

    Ok(HttpResponse::Ok().json(span_with_events))
}

#[derive(Deserialize)]
#[serde(rename_all = "camelCase")]
struct GetTraceMetricsParams {
    /// e.g. "traceCount", "traceLatency", "tokenCount", "approximateCost"
    pub metric: String,
    /// Total or average, TODO: Find better name for this field
    pub aggregation: Aggregation,
    /// Date range per page
    #[serde(default)]
    #[serde(flatten)]
    pub date_range: Option<DateRange>,
    /// Group by interval per page
    #[serde(default)]
    pub group_by_interval: GroupByInterval,
}

/// Get metrics for a single metric type (e.g. for average trace latency)
#[post("traces/metrics")]
pub async fn get_traces_metrics(
    params: web::Path<Uuid>,
    clickhouse: web::Data<clickhouse::Client>,
    req: web::Json<GetTraceMetricsParams>,
) -> ResponseResult {
    let project_id = params.into_inner();
    let clickhouse = clickhouse.into_inner().as_ref().clone();
    let req = req.into_inner();
    let metric = req.metric;
    let aggregation = req.aggregation;
    let date_range = req.date_range.as_ref();
    let group_by_interval = req.group_by_interval;

    let past_hours = match date_range {
        Some(date_range) => match date_range {
            DateRange::Absolute(_) => {
                return Err(anyhow::anyhow!("Absolute date range is not supported").into());
            }
            DateRange::Relative(interval) => {
                if interval.past_hours == "all" {
                    // Don't fetch data for more than 30 days for "all"
                    None
                } else {
                    let past_hours: i64 = interval.past_hours.parse().map_err(|_| {
                        anyhow::anyhow!(
                            "Failed to parse past_hours as i64: {}",
                            interval.past_hours
                        )
                    })?;
                    Some(past_hours)
                }
            }
        },
        // We expect client to always provide a date range. But for smooth UX, we default to 30 days
        None => None,
    };

    let past_hours = if let Some(past_hours) = past_hours {
        past_hours
    } else {
        let time_bounds = get_time_bounds(clickhouse.clone(), project_id).await?;
        if time_bounds.min_time == 0 {
            let values: Vec<IntMetricTimeValue> = vec![];
            return Ok(HttpResponse::Ok().json(values));
        }

        let past_hours = hours_ago(time_bounds.min_time);
        past_hours.max(48) // the grouping is done by 1 day
    };

    match metric.as_str() {
        "traceCount" => match aggregation {
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for traceCount metric"
                )
                .into());
            }
            Aggregation::Total => {
                let values = ch::spans::get_total_trace_count_metrics(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        "traceLatencySeconds" => match aggregation {
            Aggregation::Total => {
                return Err(anyhow::anyhow!(
                    "Total grouping is not supported for traceLatency metric"
                )
                .into());
            }
            Aggregation::Average => {
                let values = ch::spans::get_average_trace_latency_seconds_metrics(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
        },
        "totalTokenCount" => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_total_total_token_count_metrics(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for totalTokenCount metric"
                )
                .into());
            }
        },
        "costUsd" => match aggregation {
            Aggregation::Total => {
                let values = ch::spans::get_total_cost_usd_metrics(
                    clickhouse,
                    group_by_interval,
                    project_id,
                    past_hours,
                )
                .await?;

                Ok(HttpResponse::Ok().json(values))
            }
            Aggregation::Average => {
                return Err(anyhow::anyhow!(
                    "Average grouping is not supported for costUsd metric"
                )
                .into());
            }
        },
        _ => {
            return Err(anyhow::anyhow!("Unsupported metric: {}", metric).into());
        }
    }
}
